
@misc{liuLargeLanguageModels2024,
  title = {Large {{Language Models}} and {{Causal Inference}} in {{Collaboration}}: {{A Comprehensive Survey}}},
  shorttitle = {Large {{Language Models}} and {{Causal Inference}} in {{Collaboration}}},
  author = {Liu, Xiaoyu and Xu, Paiheng and Wu, Junda and Yuan, Jiaxin and Yang, Yifan and Zhou, Yuhang and Liu, Fuxiao and Guan, Tianrui and Wang, Haoliang and Yu, Tong and McAuley, Julian and Ai, Wei and Huang, Furong},
  year = {2024},
  month = mar,
  number = {arXiv:2403.09606},
  eprint = {2403.09606},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.09606},
  urldate = {2024-05-27},
  abstract = {Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective potential to further the development of more advanced and equitable artificial intelligence systems.},
  archiveprefix = {arxiv},
}

@article{anwar2024foundational,
  title={Foundational challenges in assuring alignment and safety of large language models},
  author={Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others},
  journal={arXiv preprint arXiv:2404.09932},
  year={2024}
}

@article{park2023linear,
  title={The linear representation hypothesis and the geometry of large language models},
  author={Park, Kiho and Choe, Yo Joong and Veitch, Victor},
  journal={arXiv preprint arXiv:2311.03658},
  year={2023}
}

@article{kasetty2024evaluating,
  title={Evaluating Interventional Reasoning Capabilities of Large Language Models},
  author={Kasetty, Tejas and Mahajan, Divyat and Dziugaite, Gintare Karolina and Drouin, Alexandre and Sridhar, Dhanya},
  journal={arXiv preprint arXiv:2404.05545},
  year={2024}
}

@article{jin2024cladder,
  title={{CLadder}: A benchmark to assess causal reasoning capabilities of language models},
  author={Jin, Zhijing and Chen, Yuen and Leeb, Felix and Gresele, Luigi and Kamal, Ojasv and Lyu, Zhiheng and Blin, Kevin and Gonzalez Adauto, Fernando and Kleiman-Weiner, Max and Sachan, Mrinmaya and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
# LLM for causal discovery: parrots or useful priors?
@article{zevcevic2023causal,
  title={Causal parrots: Large language models may talk causality but are not causal},
  author={Ze{\v{c}}evi{\'c}, Matej and Willig, Moritz and Dhami, Devendra Singh and Kersting, Kristian},
  journal={arXiv preprint arXiv:2308.13067},
  year={2023}
}
@article{vashishtha2023causal,
  title={Causal inference using llm-guided discovery},
  author={Vashishtha, Aniket and Reddy, Abbavaram Gowtham and Kumar, Abhinav and Bachu, Saketh and Balasubramanian, Vineeth N and Sharma, Amit},
  journal={arXiv preprint arXiv:2310.15117},
  year={2023}
}

@article{reizinger2024understanding,
  title={Understanding LLMs Requires More Than Statistical Generalization},
  author={Reizinger, Patrik and Ujv{\'a}ry, Szilvia and M{\'e}sz{\'a}ros, Anna and Kerekes, Anna and Brendel, Wieland and Husz{\'a}r, Ferenc},
  journal={arXiv preprint arXiv:2405.01964},
  year={2024}
}

# context - environments - few shot learning
@inproceedings{
gupta2024context_is_env,
title={Context is Environment},
author={Sharut Gupta and Stefanie Jegelka and David Lopez-Paz and Kartik Ahuja},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=8VPWfqtQMX}
}

@inproceedings{
lampinen2023passive,
title={Passive learning of active causal strategies in agents and language models},
author={Andrew Kyle Lampinen and Stephanie C.Y. Chan and Ishita Dasgupta and Andrew Joo Hun Nam and Jane X Wang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=BRpi8YAfac}
}

# identifiability in vision-language / multimodal
@inproceedings{
daunhawer2023identifiability,
title={Identifiability Results for Multimodal Contrastive Learning},
author={Imant Daunhawer and Alice Bizeul and Emanuele Palumbo and Alexander Marx and Julia E Vogt},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=U_2kuqoTcB}
}