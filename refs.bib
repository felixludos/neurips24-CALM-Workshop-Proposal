
@misc{liuLargeLanguageModels2024,
  title = {Large {{Language Models}} and {{Causal Inference}} in {{Collaboration}}: {{A Comprehensive Survey}}},
  shorttitle = {Large {{Language Models}} and {{Causal Inference}} in {{Collaboration}}},
  author = {Liu, Xiaoyu and Xu, Paiheng and Wu, Junda and Yuan, Jiaxin and Yang, Yifan and Zhou, Yuhang and Liu, Fuxiao and Guan, Tianrui and Wang, Haoliang and Yu, Tong and McAuley, Julian and Ai, Wei and Huang, Furong},
  year = {2024},
  month = mar,
  number = {arXiv:2403.09606},
  eprint = {2403.09606},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.09606},
  urldate = {2024-05-27},
  abstract = {Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective potential to further the development of more advanced and equitable artificial intelligence systems.},
  archiveprefix = {arxiv},
}

@article{anwar2024foundational,
  title={Foundational challenges in assuring alignment and safety of large language models},
  author={Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others},
  journal={arXiv preprint arXiv:2404.09932},
  year={2024}
}

@article{park2023linear,
  title={The linear representation hypothesis and the geometry of large language models},
  author={Park, Kiho and Choe, Yo Joong and Veitch, Victor},
  journal={arXiv preprint arXiv:2311.03658},
  year={2023}
}

@article{kasetty2024evaluating,
  title={Evaluating Interventional Reasoning Capabilities of Large Language Models},
  author={Kasetty, Tejas and Mahajan, Divyat and Dziugaite, Gintare Karolina and Drouin, Alexandre and Sridhar, Dhanya},
  journal={arXiv preprint arXiv:2404.05545},
  year={2024}
}

@article{nie2024moca,
  title={{MoCa}: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks},
  author={Nie, Allen and Zhang, Yuhui and Amdekar, Atharva Shailesh and Piech, Chris and Hashimoto, Tatsunori B and Gerstenberg, Tobias},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{jin2024cladder,
  title={{CLadder}: A benchmark to assess causal reasoning capabilities of language models},
  author={Jin, Zhijing and Chen, Yuen and Leeb, Felix and Gresele, Luigi and Kamal, Ojasv and Lyu, Zhiheng and Blin, Kevin and Gonzalez Adauto, Fernando and Kleiman-Weiner, Max and Sachan, Mrinmaya and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
# LLM for causal discovery: parrots or useful priors?
@article{zevcevic2023causal,
  title={Causal parrots: Large language models may talk causality but are not causal},
  author={Ze{\v{c}}evi{\'c}, Matej and Willig, Moritz and Dhami, Devendra Singh and Kersting, Kristian},
  journal={arXiv preprint arXiv:2308.13067},
  year={2023}
}
@article{vashishtha2023causal,
  title={Causal inference using {LLM}-guided discovery},
  author={Vashishtha, Aniket and Reddy, Abbavaram Gowtham and Kumar, Abhinav and Bachu, Saketh and Balasubramanian, Vineeth N and Sharma, Amit},
  journal={arXiv preprint arXiv:2310.15117},
  year={2023}
}

@article{reizinger2024understanding,
  title={Understanding {LLM}s Requires More Than Statistical Generalization},
  author={Reizinger, Patrik and Ujv{\'a}ry, Szilvia and M{\'e}sz{\'a}ros, Anna and Kerekes, Anna and Brendel, Wieland and Husz{\'a}r, Ferenc},
  journal={arXiv preprint arXiv:2405.01964},
  year={2024}
}

# context - environments - few shot learning
@inproceedings{
gupta2024context_is_env,
title={Context is Environment},
author={Sharut Gupta and Stefanie Jegelka and David Lopez-Paz and Kartik Ahuja},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=8VPWfqtQMX}
}

@inproceedings{
lampinen2023passive,
title={Passive learning of active causal strategies in agents and language models},
author={Andrew Kyle Lampinen and Stephanie C.Y. Chan and Ishita Dasgupta and Andrew Joo Hun Nam and Jane X Wang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=BRpi8YAfac}
}

# identifiability in vision-language / multimodal
@inproceedings{
daunhawer2023identifiability,
title={Identifiability Results for Multimodal Contrastive Learning},
author={Imant Daunhawer and Alice Bizeul and Emanuele Palumbo and Alexander Marx and Julia E Vogt},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=U_2kuqoTcB}
}

@article{kiciman2023causal,
  title={Causal reasoning and large language models: Opening a new frontier for causality},
  author={K{\i}c{\i}man, Emre and Ness, Robert and Sharma, Amit and Tan, Chenhao},
  journal={arXiv preprint arXiv:2305.00050},
  year={2023}
}

@inproceedings{
richens2024robust,
title={Robust agents learn causal world models},
author={Jonathan Richens and Tom Everitt},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=pOoKI3ouv1}
}
@inproceedings{
abdulaal2024causal,
title={Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning},
author={Ahmed Abdulaal and adamos hadjivasiliou and Nina Montana-Brown and Tiantian He and Ayodeji Ijishakin and Ivana Drobnjak and Daniel C. Castro and Daniel C. Alexander},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=pAoqRlTBtY}
}

@inproceedings{
sanchez2022diffusion,
title={Diffusion Causal Models for Counterfactual Estimation},
author={Pedro Sanchez and Sotirios A. Tsaftaris},
booktitle={First Conference on Causal Learning and Reasoning},
year={2022},
url={https://openreview.net/forum?id=LAAZLZIMN-o}
}

@inproceedings{yang2023critical,
  title={A critical review of Causal Inference benchmarks for Large Language Models},
  author={Yang, Linying and Clivio, Oscar and Shirvaikar, Vik and Falck, Fabian},
  booktitle={AAAI 2024 Workshop on''Are Large Language Models Simply Causal Parrots?''},
  year={2023}
}

@article{feder2024causal,
  title={Causal-structure Driven Augmentations for Text {OOD} Generalization},
  author={Feder, Amir and Wald, Yoav and Shi, Claudia and Saria, Suchi and Blei, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2024concept,
  title={Concept Algebra for (Score-Based) Text-Controlled Generative Models},
  author={Wang, Zihao and Gui, Lin and Negrea, Jeffrey and Veitch, Victor},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{jiang2024origins,
  title={On the origins of linear representations in large language models},
  author={Jiang, Yibo and Rajendran, Goutham and Ravikumar, Pradeep and Aragam, Bryon and Veitch, Victor},
  journal={arXiv preprint arXiv:2403.03867},
  year={2024}
}

@article{rajendran2024learning,
  title={Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models},
  author={Rajendran, Goutham and Buchholz, Simon and Aragam, Bryon and Sch{\"o}lkopf, Bernhard and Ravikumar, Pradeep},
  journal={arXiv preprint arXiv:2402.09236},
  year={2024}
}
@article{long2023causal,
  title={Causal discovery with language models as imperfect experts},
  author={Long, Stephanie and Pich{\'e}, Alexandre and Zantedeschi, Valentina and Schuster, Tibor and Drouin, Alexandre},
  journal={arXiv preprint arXiv:2307.02390},
  year={2023}
}

@article{d2022underspecification,
  title={Underspecification presents challenges for credibility in modern machine learning},
  author={D'Amour, Alexander and Heller, Katherine and Moldovan, Dan and Adlam, Ben and Alipanahi, Babak and Beutel, Alex and Chen, Christina and Deaton, Jonathan and Eisenstein, Jacob and Hoffman, Matthew D and others},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={226},
  pages={1--61},
  year={2022}
}

@article{montagna2024demystifying,
  title={Demystifying amortized causal discovery with transformers},
  author={Montagna, Francesco and Cairney-Leeming, Max and Sridhar, Dhanya and Locatello, Francesco},
  journal={arXiv preprint arXiv:2405.16924},
  year={2024}
}

@article{willig2022can,
  title={Can foundation models talk causality?},
  author={Willig, Moritz and Ze{\v{c}}evi{\'c}, Matej and Dhami, Devendra Singh and Kersting, Kristian},
  journal={arXiv preprint arXiv:2206.10591},
  year={2022}
}

@inproceedings{geiger2024finding,
  title={Finding alignments between interpretable causal variables and distributed neural representations},
  author={Geiger, Atticus and Wu, Zhengxuan and Potts, Christopher and Icard, Thomas and Goodman, Noah},
  booktitle={Causal Learning and Reasoning},
  pages={160--187},
  year={2024},
  organization={PMLR}
}

@article{pan2024counterfactual,
  title={Counterfactual Image Editing},
  author={Pan, Yushu and Bareinboim, Elias},
  journal={arXiv preprint arXiv:2403.09683},
  year={2024}
}

@inproceedings{li2024steering,
  title={Steering {LLM}s Towards Unbiased Responses: A Causality-Guided Debiasing Framework},
  author={Li, Jingling and Tang, Zeyu and Liu, Xiaoyu and Spirtes, Peter and Zhang, Kun and Leqi, Liu and Liu, Yang},
  booktitle={ICLR 2024 Workshop on Reliable and Responsible Foundation Models}
}

@article{xia2021causal,
  title={The causal-neural connection: Expressiveness, learnability, and inference},
  author={Xia, Kevin and Lee, Kai-Zhan and Bengio, Yoshua and Bareinboim, Elias},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10823--10836},
  year={2021}
}

@article{wu2024interpretability,
  title={Interpretability at scale: Identifying causal mechanisms in alpaca},
  author={Wu, Zhengxuan and Geiger, Atticus and Icard, Thomas and Potts, Christopher and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}