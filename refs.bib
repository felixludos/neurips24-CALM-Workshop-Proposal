
@misc{liuLargeLanguageModels2024,
  title = {Large {{Language Models}} and {{Causal Inference}} in {{Collaboration}}: {{A Comprehensive Survey}}},
  shorttitle = {Large {{Language Models}} and {{Causal Inference}} in {{Collaboration}}},
  author = {Liu, Xiaoyu and Xu, Paiheng and Wu, Junda and Yuan, Jiaxin and Yang, Yifan and Zhou, Yuhang and Liu, Fuxiao and Guan, Tianrui and Wang, Haoliang and Yu, Tong and McAuley, Julian and Ai, Wei and Huang, Furong},
  year = {2024},
  month = mar,
  number = {arXiv:2403.09606},
  eprint = {2403.09606},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.09606},
  urldate = {2024-05-27},
  abstract = {Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective potential to further the development of more advanced and equitable artificial intelligence systems.},
  archiveprefix = {arxiv},
}
